{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Relative contributions of Shakespeare and Fletcher in Henry VIII: An Analysis Based on Most Frequent Words and Most Frequent Rhythmic Patterns</h1>\n",
    "<h2 style='margin-bottom: 50px'>Replication code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.stats import zscore\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read data from JSON</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------#\n",
    "# the file contains a list of scenes each of them being a dict with following structure:  #   \n",
    "# {                                                                                       #\n",
    "#     'author': string ('Shakespeare', 'Fletcher', 'Massinger', 'target'),                #\n",
    "#     'play': string ('Coriolanus', 'Cymbeline'...),                                      #\n",
    "#     'id': string ('1.1', '1.2'...),                                                     #\n",
    "#     'lines': [                                                                          #\n",
    "#         'words': list (~ list of words in the line),                                    #\n",
    "#         'stress': string (~ bitstring representing rhythmic type),                      #\n",
    "#     ]                                                                                   #\n",
    "# }                                                                                       #\n",
    "# Dataset comes from EarlyPrint project (http://earlyprint.org), rhythmical annotation    #\n",
    "# was provided by Prosodic python package (https://github.com/quadrismegistus/prosodic)   #\n",
    "#-----------------------------------------------------------------------------------------#\n",
    "\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Remove scenes from the training set having less than 100 lines \n",
    "# Remove 5.2 from Henry VIII (mostly prose)\n",
    "data = [x for x in data if (len(x['lines']) >= 100 or (x['play'] == 'Henry VIII' and x['id'] != '5.2'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of lines and number of words in each scene\n",
    "# (store word counts for further use)\n",
    "words_count_scenes = list() \n",
    "for scene in data:\n",
    "    lines_count = len(scene['lines'])\n",
    "    words_count = 0\n",
    "    for line in scene['lines']:\n",
    "        for word in line['words']:\n",
    "            words_count += 1\n",
    "    words_count_scenes.append(words_count)\n",
    "    print(scene['play'], scene['id'], lines_count, words_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scenes to vectors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = {'stress': [], 'words': []}\n",
    "frequencies = {'stress': [], 'words': []}\n",
    "\n",
    "# Iterate over scenes and add each rhythmic type and word to overall list\n",
    "for scene in data:\n",
    "    if scene['play'] == 'Henry VIII': # skip the target text\n",
    "        continue\n",
    "    for line in scene['lines']:\n",
    "        most_frequent['stress'].append(line['stress'])\n",
    "        for word in line['words']:\n",
    "            most_frequent['words'].append(word)\n",
    "        \n",
    "# Extract 500 most frequent rhythmic types and 500 most frequent words\n",
    "for m in most_frequent:\n",
    "    c = Counter(most_frequent[m])\n",
    "    most_frequent[m] = [ x[0] for x in c.most_common(500) ]    \n",
    "\n",
    "# Iterate over scenes and count the frequencies of 500 most frequent words and \n",
    "# 500 most frequent rhythmic types in particular scenes\n",
    "for i, scene in enumerate(data):\n",
    "    f = {'words':defaultdict(int), 'stress': defaultdict(int)}\n",
    "\n",
    "    for line in scene['lines']:\n",
    "        if line['stress'] in most_frequent['stress']:                \n",
    "            f['stress'][line['stress']] += 1/len(scene['lines'])\n",
    "        for word in line['words']:\n",
    "            if word in most_frequent['words']:      \n",
    "                f['words'][word] += 1/words_count_scenes[i]\n",
    "    for t in f:\n",
    "        frequencies[t].append(f[t])\n",
    "    \n",
    "# Store frequencies into dataframes\n",
    "index = pd.MultiIndex.from_tuples([(x['author'], x['play'], x['id']) for x in data], \n",
    "                                  names=['author', 'play', 'scene'])\n",
    "df = dict()\n",
    "df['stress'] = pd.DataFrame(frequencies['stress'], index=index).fillna(0)\n",
    "df['words'] =  pd.DataFrame(frequencies['words'], index=index).fillna(0)\n",
    "df['combined'] = pd.concat([df['stress'], df['words']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross-validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_set(df, current_play):\n",
    "    '''\n",
    "    Extract test set (single play) from the dataframe\n",
    "    [arg] df            = dataframe\n",
    "    [arg] current_play  = title of the play which is\n",
    "    [out] test_vectors  = list of vectors representing individual scenes\n",
    "    [out] test_class    = actual author of the play\n",
    "    [out] test_labels   = labels for output (author: play(scene))\n",
    "    '''\n",
    "\n",
    "    test_data = df.iloc[df.index.get_level_values('play') == current_play]\n",
    "    test_vectors = test_data.values.tolist()\n",
    "    test_class = test_data.index.get_level_values('author').unique().tolist()[0]\n",
    "    test_labels = ['{0}: {1}({2})'.format(author, play, scene) for author, play, scene in test_data.index.tolist()]\n",
    "    return test_vectors, test_class, test_labels\n",
    "\n",
    "\n",
    "def extract_train_set(df, current_play=None):\n",
    "    '''\n",
    "    Extract training set from the dataframe\n",
    "    [arg] df            = dataframe\n",
    "    [arg] current_play  = title of the play to exclude from the training set (optional)\n",
    "    [out] train_vectors = list of vectors representing individual scenes\n",
    "    [out] train_classes = actual authors of individual scenes\n",
    "    [out] level_to      = minimum of scenes by one author\n",
    "    '''\n",
    "\n",
    "    train_data = df.iloc[df.index.get_level_values('play') != current_play]\n",
    "    train_vectors = train_data.values.tolist()\n",
    "    train_classes = train_data.index.get_level_values('author').tolist()\n",
    "    level_to = min(Counter(train_classes).values())    \n",
    "    return train_vectors, train_classes, level_to\n",
    "\n",
    "def classify(train_vectors, train_classes, test_vectors, level_to, allow_probs=False):\n",
    "    '''\n",
    "    Train the model and perform classification\n",
    "    [arg] train_vectors = list of training vectors\n",
    "    [arg] train_classes = actual authors of training samples\n",
    "    [arg] test_vectors  = list of vectors to be classified\n",
    "    [arg] level_to      = minimum of scenes by one author\n",
    "    [out] predicted     = list of classification results \n",
    "    '''\n",
    "    \n",
    "    # Extract scene indices for each author\n",
    "    authors_indices = defaultdict(list)\n",
    "    for i, author in enumerate(train_classes):\n",
    "        authors_indices[author].append(i)\n",
    "    leveled_indices = list()\n",
    "\n",
    "    # Level the number of training data by random\n",
    "    for author in authors_indices:\n",
    "        leveled_indices.extend(random.sample(authors_indices[author], level_to))\n",
    "    train_vectors_leveled = [x for i,x in enumerate(train_vectors) if i in leveled_indices]\n",
    "    train_classes_leveled = [x for i,x in enumerate(train_classes) if i in leveled_indices]\n",
    "\n",
    "    # Fit the classifier to training data\n",
    "    if allow_probs:\n",
    "        clf = SVC(kernel='linear', C=1, probability=True)\n",
    "    else:\n",
    "        clf = SVC(kernel='linear', C=1)        \n",
    "    clf.fit(train_vectors_leveled, train_classes_leveled)\n",
    "            \n",
    "    # Perform classification of test set\n",
    "    predicted = clf.predict(test_vectors)  \n",
    "    \n",
    "    if allow_probs:\n",
    "        probs = clf.predict_proba(test_vectors)\n",
    "        return predicted, probs, clf.classes_\n",
    "    else:\n",
    "        return predicted\n",
    "    \n",
    "# Z-scores transformation of training data\n",
    "dfz = dict()\n",
    "for f in df:\n",
    "    dfz[f] = df[f].loc[['Shakespeare', 'Fletcher', 'Massinger']].apply(zscore)\n",
    "\n",
    "# Get play titles\n",
    "play_titles = dfz['stress'].index.get_level_values('play').unique().tolist()\n",
    "\n",
    "# Container for cross-validation results\n",
    "cv_results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over plays\n",
    "for current_play in play_titles:\n",
    "\n",
    "    # Iterate over feature sets (stress, word, combined)\n",
    "    for f in dfz:\n",
    "\n",
    "        # Extract training and test sets\n",
    "        test_vectors, test_class, test_labels = extract_test_set(dfz[f], current_play)\n",
    "        train_vectors, train_classes, level_to = extract_train_set(dfz[f], current_play)\n",
    "\n",
    "        # Perform 30 random iterations\n",
    "        for iteration in range(30):\n",
    "\n",
    "            # Train the model and classify test set\n",
    "            predicted = classify(train_vectors, train_classes, test_vectors, level_to)\n",
    "            \n",
    "            # Store classification result for each scene\n",
    "            for i,p in enumerate(predicted):\n",
    "                if p == test_class:\n",
    "                    cv_results[test_labels[i]][f] += 1\n",
    "                else:\n",
    "                    cv_results[test_labels[i]][f] += 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results of cross-validation (number of correct classifications for each scene provided by models\n",
    "# based on (1) rhythmic types, (2) words, (3) combined vectors)                    \n",
    "for scene in sorted(cv_results):\n",
    "    print(scene, cv_results[scene]['stress'], cv_results[scene]['words'], cv_results[scene]['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results of cross-validation as a portion of correct classifications per play\n",
    "cv_results_per_play = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for scene in sorted(cv_results):\n",
    "    play_title = re.sub('\\(.*$', '', scene)\n",
    "    for f in cv_results[scene]:\n",
    "        cv_results_per_play[play_title][f].append(cv_results[scene][f])\n",
    "        \n",
    "for play in sorted(cv_results_per_play):\n",
    "    for f in cv_results_per_play[play]:\n",
    "        cv_results_per_play[play][f] = sum(cv_results_per_play[play][f]) / (len(cv_results_per_play[play][f])*30)\n",
    "    print(play, cv_results_per_play[play]['stress'], \n",
    "          cv_results_per_play[play]['words'], cv_results_per_play[play]['combined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification of Henry VIII</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-scores transformation of all data\n",
    "dfz = dict()\n",
    "for f in df:\n",
    "    dfz[f] = df[f].apply(zscore)\n",
    "\n",
    "# Get play titles\n",
    "play_titles = dfz['combined'].index.get_level_values('play').unique().tolist()\n",
    "\n",
    "# Container for classification results\n",
    "henry_results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Extract training and test sets\n",
    "test_vectors, test_class, test_labels = extract_test_set(dfz['combined'], 'Henry VIII')\n",
    "train_vectors, train_classes, level_to = extract_train_set(dfz['combined'], 'Henry VIII')\n",
    "\n",
    "# Perform 30 random iterations\n",
    "for iteration in range(30):\n",
    "\n",
    "    # Perform, classification of test set\n",
    "    predicted = classify(train_vectors, train_classes, test_vectors, level_to)\n",
    "            \n",
    "    # Store classification result for each scene\n",
    "    for i,p in enumerate(predicted):\n",
    "        henry_results[test_labels[i]][p] += 1\n",
    "\n",
    "# Print results\n",
    "for scene in sorted(henry_results):\n",
    "    print(scene)\n",
    "    for author in henry_results[scene]:\n",
    "        print('\\t', author, henry_results[scene][author])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Rolling attribution</h2>\n",
    "\n",
    "<h3>extract samples</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from JSON once again (to get the removed short scenes back)\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Merge the scenes of each play into single list\n",
    "plays_merged = defaultdict(list)\n",
    "plays_authors = dict()\n",
    "for i, scene in enumerate(data):\n",
    "    if scene['author'] == 'Massinger':\n",
    "        continue\n",
    "    plays_merged[scene['play']].extend(scene['lines'])\n",
    "    plays_authors[scene['play']] = scene['author']\n",
    "\n",
    "# Count frequencies in rolling samples\n",
    "index1 = list()\n",
    "index2 = list()\n",
    "frequencies_samples = {'stress': [], 'words': []}\n",
    "frequencies_rolling = {'stress': [], 'words': []}\n",
    "\n",
    "# Iterate over plays\n",
    "for play in plays_merged:    \n",
    "    i = 0\n",
    "    # Iterate over 100-lines long overlapping samples\n",
    "    while i <= len(plays_merged[play]) - 100:\n",
    "\n",
    "        # Extract the sample from the play\n",
    "        frame = plays_merged[play][i:i+100]\n",
    "\n",
    "        # Count frequencies in the sample\n",
    "        index2.append((plays_authors[play], play+'_rolling', (i+5)/5))\n",
    "        f_rolling = {'words':defaultdict(int), 'stress': defaultdict(int)}\n",
    "        n = 0\n",
    "        for line in frame:\n",
    "            if line['stress'] in most_frequent['stress']:                \n",
    "                f_rolling['stress'][line['stress']] += 1/len(frame)\n",
    "            for word in line['words']:\n",
    "                if word in most_frequent['words']:      \n",
    "                    f_rolling['words'][word] += 1  \n",
    "                n += 1\n",
    "\n",
    "        # Word counts into relative frequencies\n",
    "        for word in f_rolling['words']:\n",
    "            f_rolling['words'][word] /= n\n",
    "\n",
    "        # Store frequencies into main container of overlapping samples\n",
    "        for t in f_rolling:\n",
    "            frequencies_rolling[t].append(f_rolling[t])\n",
    "\n",
    "        # If sample index % 20: store frequencies into main container of non-overlapping samples\n",
    "        if i % 20 == 0 and play != 'Henry VIII':\n",
    "            index1.append((plays_authors[play], play, (i+20)/20))\n",
    "            for t in f_rolling:\n",
    "                frequencies_samples[t].append(f_rolling[t])\n",
    "        i += 5\n",
    "        \n",
    "# Store frequencies into dataframes (non-overlapping samples)\n",
    "index1 = pd.MultiIndex.from_tuples(index1, names=['author', 'play', 'scene'])\n",
    "dfr1 = dict()\n",
    "dfr1['stress'] = pd.DataFrame(frequencies_samples['stress'], index=index1).fillna(0)\n",
    "dfr1['words'] =  pd.DataFrame(frequencies_samples['words'], index=index1).fillna(0)\n",
    "dfr1['combined'] = pd.concat([dfr1['stress'], dfr1['words']], axis=1)\n",
    "\n",
    "# Store frequencies into dataframes (overlapping samples)\n",
    "index2 = pd.MultiIndex.from_tuples(index2, names=['author', 'play', 'scene'])\n",
    "dfr2 = dict()\n",
    "dfr2['stress'] = pd.DataFrame(frequencies_rolling['stress'], index=index2).fillna(0)\n",
    "dfr2['words'] =  pd.DataFrame(frequencies_rolling['words'], index=index2).fillna(0)\n",
    "dfr2['combined'] = pd.concat([dfr2['stress'], dfr2['words']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>apply to training set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get play titles\n",
    "play_titles = dfr1['combined'].index.get_level_values('play').unique().tolist()\n",
    "\n",
    "# Container for results\n",
    "rolling_results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Iterate over plays\n",
    "for current_play in play_titles:\n",
    "    \n",
    "    rr = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Concat the df with rolling samples from the play, trasform values to z-scores and remove rows on current_play\n",
    "    dfr = pd.concat([dfr1['combined'],dfr2['combined'].iloc[dfr2['combined'].index.get_level_values('play') == current_play+'_rolling']])\n",
    "    dfz = dfr.apply(zscore)\n",
    "    dfz = dfz.iloc[dfz.index.get_level_values('play') != current_play]\n",
    "\n",
    "    # Extract training and test sets\n",
    "    train_vectors, train_classes, level_to = extract_train_set(dfz, current_play+'_rolling')\n",
    "    test_vectors, test_class, test_labels = extract_test_set(dfz, current_play+'_rolling')\n",
    "    \n",
    "    # Perform 30 random iterations\n",
    "    for iteration in range(30):\n",
    "\n",
    "        # Train the model and classify rolling samples\n",
    "        predicted, probs, classes = classify(train_vectors, train_classes, test_vectors, level_to, allow_probs=True)\n",
    "\n",
    "        # Store the results\n",
    "        for i,x in enumerate(probs):\n",
    "            for c in (0,1):\n",
    "                for j in range(20):\n",
    "                    if classes[c] == 'Shakespeare':\n",
    "                        rr[classes[c]][i+j].append(x[c]) \n",
    "                    else:\n",
    "                        rr[classes[c]][i+j].append((-1) * x[c]) \n",
    "\n",
    "    # Count the average probability for each 5-lines sequence\n",
    "    for c in rr:\n",
    "        for i in sorted(rr[c]):\n",
    "            rolling_results[current_play][c].append(sum(rr[c][i])/len(rr[c][i]))      \n",
    "            if c == 'Shakespeare':\n",
    "                line_val = (\n",
    "                    (\n",
    "                        ( \n",
    "                            sum(rr['Shakespeare'][i])/len(rr['Shakespeare'][i])\n",
    "                        ) + (\n",
    "                            sum(rr['Fletcher'][i])/len(rr['Fletcher'][i])\n",
    "                        )\n",
    "                    )/2\n",
    "                )\n",
    "                rolling_results[current_play]['line'].append(line_val)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the charts\n",
    "ax = [None] * len(rolling_results)\n",
    "fig, ax = plt.subplots(len(ax), 1, sharex=True, figsize=(20, 50))\n",
    "\n",
    "i = 0\n",
    "for play in sorted(rolling_results):\n",
    "    x = range(len(rolling_results[play]['Shakespeare']))\n",
    "    ax[i].fill_between(x, 0, rolling_results[play]['Shakespeare'], facecolor='#957DAD', interpolate=True)\n",
    "    ax[i].fill_between(x, 0, rolling_results[play]['Fletcher'], facecolor='#7CAA98', interpolate=True)\n",
    "    ax[i].plot(x, rolling_results[play]['line'], color='black', linewidth=3)\n",
    "    ax[i].set_ylim(-1.2,1.2)\n",
    "    ax[i].set_ylabel(play, fontsize=18)              \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>apply to Henry VIII</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for results\n",
    "rolling_results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "for f in dfr1:\n",
    "\n",
    "    # Get play titles\n",
    "    dfr1b = dfr1[f].loc[['Shakespeare', 'Fletcher']]\n",
    "    play_titles = dfr1b.index.get_level_values('play').unique().tolist()\n",
    "\n",
    "    rr = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Concat the df with rolling samples from the play, trasform values to z-scores and remove rows on current_play\n",
    "    dfr = pd.concat([dfr1b,dfr2[f].iloc[dfr2[f].index.get_level_values('play') == 'Henry VIII_rolling']])\n",
    "    dfz = dfr.apply(zscore)\n",
    "\n",
    "    # Extract training and test sets\n",
    "    train_vectors, train_classes, level_to = extract_train_set(dfz, 'Henry VIII_rolling')\n",
    "    test_vectors, test_class, test_labels = extract_test_set(dfz, 'Henry VIII_rolling')\n",
    "\n",
    "    train_vectors = [train_vectors[i] for i,x in enumerate(train_classes) if x != 'Massinger']\n",
    "    train_classes = [x for i,x in enumerate(train_classes) if x != 'Massinger']\n",
    "    \n",
    "    # Perform 30 random iterations\n",
    "    for iteration in range(30):\n",
    "\n",
    "        # Train the model and classify rolling samples\n",
    "        predicted, probs, classes = classify(train_vectors, train_classes, test_vectors, level_to, allow_probs=True)\n",
    "\n",
    "        # Store the results\n",
    "        for i,x in enumerate(probs):\n",
    "            for c in (0,1):\n",
    "                for j in range(20):\n",
    "                    if classes[c] == 'Shakespeare':\n",
    "                        rr[classes[c]][i+j].append(x[c]) \n",
    "                    else:\n",
    "                        rr[classes[c]][i+j].append((-1) * x[c])\n",
    "\n",
    "    # Count the average probability for each 5-lines sequence                        \n",
    "    for c in rr:\n",
    "        for i in sorted(rr[c]):\n",
    "            rolling_results['Henry VIII'][f][c].append(sum(rr[c][i])/len(rr[c][i]))      \n",
    "            if c == 'Shakespeare':\n",
    "                line_val = (\n",
    "                    (\n",
    "                        ( \n",
    "                            sum(rr['Shakespeare'][i])/len(rr['Shakespeare'][i])\n",
    "                        ) + (\n",
    "                            sum(rr['Fletcher'][i])/len(rr['Fletcher'][i])\n",
    "                        )\n",
    "                    )/2\n",
    "                )\n",
    "                rolling_results['Henry VIII'][f]['line'].append(line_val)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chart\n",
    "x = range(len(rolling_results['Henry VIII']['combined']['Shakespeare']))\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.fill_between(x, 0, rolling_results['Henry VIII']['combined']['Shakespeare'], facecolor='#957DAD', interpolate=True)\n",
    "plt.fill_between(x, 0, rolling_results['Henry VIII']['combined']['Fletcher'], facecolor='#7CAA98', interpolate=True)\n",
    "plt.plot(x, rolling_results['Henry VIII']['combined']['line'], color='black', linewidth=3)\n",
    "plt.plot(x, rolling_results['Henry VIII']['stress']['line'], color='black', dashes=[6,2])\n",
    "plt.plot(x, rolling_results['Henry VIII']['words']['line'], color='black', dashes=[2,2])\n",
    "plt.ylim(-1,1)\n",
    "plt.ylabel('Henry VIII', fontsize=18);             \n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
